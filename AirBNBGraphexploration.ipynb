{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "os.chdir('/home/aplstudent/Max_Dickinson')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#the goal right now is to get data with timeseries and categories and target to be usable\n",
    "##then i will clean it by dropping all the rows that have a nan in them\n",
    "#then i will clean it by dropping all the columns that have a nan in them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loaddata():\n",
    "        data = pd.read_csv('train_users_2.csv')\n",
    "        datatest  = pd.read_csv('test_users.csv')\n",
    "        return [data , datatest]\n",
    "data , datatest = loaddata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## get years and months as a number so it can be a category \n",
    "\n",
    "def dataAugment(data , train = False): \n",
    "    def getyear(x):\n",
    "        if type(x) == float:\n",
    "            return -1\n",
    "        else :\n",
    "            return int(x[0:4])\n",
    "    def getmonth(x):\n",
    "        if type(x) == float:\n",
    "            return -1\n",
    "        else :\n",
    "            return int(x[5:7])\n",
    "    def getday(x):\n",
    "        if type(x) == float:\n",
    "            return -1\n",
    "        else :\n",
    "            return int(x[8:11])\n",
    "    def getorder(x):\n",
    "        return( (x[0:4],x[5:7],x[8:11]) )\n",
    "    def getdate(x):\n",
    "        return datetime.date(x).toordinal()\n",
    "    def dayssince(x):\n",
    "        import matplotlib.dates as dates\n",
    "        return dates.datestr2num(x)\n",
    "    data['year_created'] = data['date_account_created'].apply(getyear)\n",
    "    data['month_created'] = data['date_account_created'].apply(getmonth)\n",
    "    data['date_created'] = data['date_account_created'].apply(getday)\n",
    "    data['num_created'] = data['date_account_created'].apply(dayssince)\n",
    "    if train ==True:\n",
    "        data['year_booked'] = data['date_first_booking'].apply(getyear)\n",
    "        data['month_booked'] = data['date_first_booking'].apply(getmonth)\n",
    "        data['day_booked'] = data['date_first_booking'].apply(getday)\n",
    "        data['num_booked'] = data['date_first_booking'].dropna().apply(dayssince) #subset of data\n",
    "    return data\n",
    "out= dataAugment(data , train =True)\n",
    "outtest = dataAugment(datatest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def createohe(data):\n",
    "    #get common axis names\n",
    "    print(\"runing\")\n",
    "    ohe = pd.get_dummies(data[['date_created', 'month_created', 'month_booked' , 'day_booked' , 'gender' , 'signup_method', 'signup_flow' , 'language' , 'affiliate_channel' , 'affiliate_provider' , 'first_affiliate_tracked', 'signup_app', 'first_device_type' , 'first_browser']])\n",
    "    #ohetest = pd.get_dummies(datatest[['date_created', 'month_created' , 'gender' , 'signup_method', 'signup_flow' , 'language' , 'affiliate_channel' , 'affiliate_provider' , 'first_affiliate_tracked', 'signup_app', 'first_device_type' , 'first_browser']])\n",
    "    #comb = pd.concat((ohe.T, ohetest.T) , join = 'outer')\n",
    "    #add age and number time columns\n",
    "    age = data[data['age'] < 100].merge(data[data['age']>14] , how = 'inner' , on = 'age') #subset of data\n",
    "    minda = pd.concat((ohe, age.age), axis = 1 , join = 'outer' ) \n",
    "    mindat = pd.concat(( minda, data['num_created']), axis = 1) #add sequential dates\n",
    "    xtrain = pd.concat(( mindat, data['num_booked']), axis = 1 , join = 'outer') #add sequential date booked\n",
    "    #splitintothree\n",
    "    #datad = mindata.dropna(axis = 1 , how= 'any') ##drop na's in all columns\n",
    "    ##age = datatest[datatest['age'] < 100].merge(datatest[datatest['age']>14] , how = 'inner' , on = 'age') #subset of data\n",
    "    #minda = pd.concat((comb.T, age.age), axis = 1 , join = 'outer' ) \n",
    "    #mindat = pd.concat(( minda, datatest['num_created']), axis = 1) #add sequential dates\n",
    "    ##print(\"runing\")\n",
    "    #xtest = pd.concat(( mindat, datatest['num_booked']), axis = 1 , join = 'outer')\n",
    "    #datadr = mindata.dropna(axis = 0 , how= 'any') ##drop na's in rows\n",
    "    xtrain = xtrain.fillna(-1)\n",
    "    #xtest = xtest.fillna(-1)\n",
    "    return xtrain\n",
    "\n",
    "xtrain = createohe(out)  \n",
    "xtest = createohe(outtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def CountryCleaner(x):\n",
    "    if x == 'NDF':\n",
    "        x = 12\n",
    "    elif x == 'US':\n",
    "        x=0\n",
    "    elif x == 'FR':\n",
    "        x=1\n",
    "    elif x == 'CA':\n",
    "        x=2\n",
    "    elif x == 'GB':\n",
    "        x=3\n",
    "    elif x == 'ES':\n",
    "        x=4\n",
    "    elif x == 'IT':\n",
    "        x=5\n",
    "    elif x == 'PT':\n",
    "        x=7\n",
    "    elif x == 'NL':\n",
    "        x=8\n",
    "    elif x =='AU':\n",
    "        x=11\n",
    "    elif x =='NDF':\n",
    "        x=10\n",
    "    elif x =='DE':\n",
    "        x=9\n",
    "    elif x =='other':\n",
    "        x =13\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mergedata(datadrop , data):\n",
    "    allt = data['country_destination'].apply(CountryCleaner)\n",
    "    dropcol = pd.concat((datadrop,allt) ,axis = 1 , join = 'inner')\n",
    "    targets = dropcol['country_destination']\n",
    "    train = dropcol.drop('country_destination' , 1)\n",
    "    return train, targets\n",
    "#col ,coltarg = mergedata(datac, out) \n",
    "#row, rowtarg = mergedata(datar, out)\n",
    "xtrain , ytrain = mergedata(xtrain, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(213451, 24)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runing\n"
     ]
    }
   ],
   "source": [
    "#get all ages between 14 and 100\n",
    "ohe = pd.get_dummies(out[['date_created', 'month_created', 'month_booked' , 'day_booked' , 'gender' , 'signup_method', 'signup_flow' , 'language' , 'affiliate_channel' , 'affiliate_provider' , 'first_affiliate_tracked', 'signup_app', 'first_device_type' , 'first_browser']])\n",
    "ohetest = pd.get_dummies(outtest[['date_created', 'month_created' , 'gender' , 'signup_method', 'signup_flow' , 'language' , 'affiliate_channel' , 'affiliate_provider' , 'first_affiliate_tracked', 'signup_app', 'first_device_type' , 'first_browser']])\n",
    "#comb = pd.concat((ohe.T, ohetest.T) , join = 'outer')\n",
    "print(\"runing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#age = out[out['age'] < 100].merge(out[out['age']>14] , how = 'inner' , on = 'age') #subset of data\n",
    "age = pd.concat((out[out['age'] < 100] , out[out['age']>14]) , join = 'inner', axis =1) #subset of data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'comb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-731fa1f9359a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mminda\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcomb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mjoin\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'outer'\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'comb' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "minda = pd.concat((comb.T, age.age), axis = 1 , join = 'outer' ) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'minda' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-71e8d6a73ce8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmindat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mminda\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'num_created'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#add sequential dates\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mxtrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mmindat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'num_booked'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mjoin\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'outer'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#add sequential date booked\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'minda' is not defined"
     ]
    }
   ],
   "source": [
    "mindat = pd.concat(( minda, out['num_created']), axis = 1) #add sequential dates\n",
    "xtrain = pd.concat(( mindat, out['num_booked']), axis = 1 , join = 'outer') #add sequential date booked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runing\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'comb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-fed3ab1bb586>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#datad = mindata.dropna(axis = 1 , how= 'any') ##drop na's in all columns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#age = outtest[outtest['age'] < 100].merge(outtest[outtest['age']>14] , how = 'inner' , on = 'age') #subset of data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mminda\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcomb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mjoin\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'outer'\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mxtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mminda\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouttest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'num_created'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#add sequential datesprint(\"runing\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m#xtest = pd.concat(( mindat, datatest['num_booked']), axis = 1 , join = 'outer')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'comb' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "#splitintothree\n",
    "print(\"runing\")\n",
    "#datad = mindata.dropna(axis = 1 , how= 'any') ##drop na's in all columns\n",
    "#age = outtest[outtest['age'] < 100].merge(outtest[outtest['age']>14] , how = 'inner' , on = 'age') #subset of data\n",
    "minda = pd.concat((comb.T, age.age), axis = 1 , join = 'outer' ) \n",
    "xtest = pd.concat(( minda, outtest['num_created']), axis = 1) #add sequential datesprint(\"runing\")\n",
    "#xtest = pd.concat(( mindat, datatest['num_booked']), axis = 1 , join = 'outer')\n",
    "#datadr = mindata.dropna(axis = 0 , how= 'any') ##drop na's in rows\n",
    "print(\"runing\")\n",
    "xtrain = xtrain.fillna(-1)\n",
    "xtest = xtest.fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def gausianfit(data,targets):\n",
    "    ##i want to make a learning curve\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "    from sklearn.feature_selection import SelectKBest\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    from sklearn.svm import SVC\n",
    "    from sklearn.decomposition import PCA\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    from sklearn.grid_search import GridSearchCV\n",
    "    from sklearn.preprocessing import Normalizer\n",
    "    #split train and validation sets\n",
    "    valid = data.loc[0:50000 , :]\n",
    "    train = data.loc[50000:: , :]\n",
    "    validy = targets.loc[0:50000 ]\n",
    "    trainy= targets.loc[50000::]\n",
    "    combined_features = FeatureUnion([(\"norm\" ,Normalizer()),(\"pca\", PCA()), (\"univ_select\", SelectKBest())])\n",
    "    estimators = [ ('comb_features' ,combined_features) , ('gnb', GaussianNB())]\n",
    "    clf = Pipeline(estimators)\n",
    "    \n",
    "    param_grid = dict(comb_features__univ_select__k=[4,10] , comb_features__pca__n_components=[2,8])\n",
    "    # Maybe some original features where good, too?\n",
    "    # Build estimator from PCA and Univariate selection:\n",
    "    grid_search = GridSearchCV(clf, param_grid=param_grid, verbose=10)\n",
    "    grid_search.fit(train , trainy).predict_proba(xtest) \n",
    "\n",
    "        \n",
    "    id_test = datatest['id']\n",
    "    ids = []  #list of ids\n",
    "    cts = []  #list of countries\n",
    "    for i in range(len(id_test)):\n",
    "        idx = id_test[i]\n",
    "        ids += [idx] * 5\n",
    "        cts += le.inverse_transform(np.argsort(y_pred[i])[::-1])[:5].tolist()\n",
    "\n",
    "    #Generate submission\n",
    "    sub = pd.DataFrame(np.column_stack((ids, cts)), columns=['id', 'country'])\n",
    "    sub.to_csv('Air.csv',index=False)\n",
    "    return\n",
    "#gausianfit(col, coltarg)\n",
    "#gausianfit(row, rowtarg)\n",
    "gausianfit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gausianfit(data):\n",
    "    ##i want to make a learning curve\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "    from sklearn.feature_selection import SelectKBest\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    from sklearn.svm import SVC\n",
    "    from sklearn.decomposition import PCA\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    from sklearn.grid_search import GridSearchCV\n",
    "    from sklearn.preprocessing import Normalizer\n",
    "    #split train and validation sets\n",
    "    #valid = data.loc[0:50000 , :]\n",
    "    #train = data.loc[50000:: , :]\n",
    "    #validy = targets.loc[0:50000 ]\n",
    "    #trainy= targets.loc[50000::]\n",
    "    \n",
    "    \n",
    "    combined_features = FeatureUnion([(\"norm\" ,Normalizer()),(\"pca\", PCA()), (\"univ_select\", SelectKBest())])\n",
    "    estimators = [ ('comb_features' ,combined_features) , ('gnb', GaussianNB())]\n",
    "    clf = Pipeline(estimators)\n",
    "    \n",
    "    param_grid = dict(comb_features__univ_select__k=[4,10] , comb_features__pca__n_components=[2,8])\n",
    "    # Maybe some original features where good, too?\n",
    "    # Build estimator from PCA and Univariate selection:\n",
    "    grid_search = GridSearchCV(clf, param_grid=param_grid, verbose=10)\n",
    "    grid_search.predict_proba(data) \n",
    "\n",
    "        \n",
    "    id_test = data['id']\n",
    "    ids = []  #list of ids\n",
    "    cts = []  #list of countries\n",
    "    for i in range(len(id_test)):\n",
    "        idx = id_test[i]\n",
    "        ids += [idx]\n",
    "        cts += le.inverse_transform(np.argsort(y_pred[i])[::-1]).tolist()\n",
    "\n",
    "    #Generate submission\n",
    "    sub = pd.DataFrame(np.column_stack((ids, cts)), columns=['id', 'country'])\n",
    "    sub.to_csv('Air.csv',index=False)\n",
    "    return\n",
    "#gausianfit(col, coltarg)\n",
    "#gausianfit(row, rowtarg)\n",
    "gausianfit(datatest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "dropcol = pd.concat((datac,allt) ,axis = 1 , join = 'inner')\n",
    "droprow = pd.concat((datar , allt) , axis = 1 , join = 'inner')\n",
    "filldata = pd.concat((filldata , allt) , axis = 1 , join= 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "targets = dropcol['country_destination']\n",
    "terg = droprow['country_destination']\n",
    "filltargets = data['country_destination']\n",
    "\n",
    "\n",
    "train = dropcol.drop('country_destination' , 1)\n",
    "train2 = droprow.drop('country_destination', 1)\n",
    "filltargets = filldata.drop('country_destination', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf.fit(train , filltargets).score(valid, validy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def throwNan(data):\n",
    "    import numpy as np\n",
    "    #dummies of categorical and times\n",
    "    mind = pd.get_dummies(nndata[['date_created', 'month_created', 'month_booked' , 'day_booked' , 'gender' , 'signup_method', 'signup_flow' , 'language' , 'affiliate_channel' , 'affiliate_provider' , 'first_affiliate_tracked', 'signup_app', 'first_device_type' , 'first_browser']])\n",
    "    minda = pd.DataFrame(np.empty((0,0)))\n",
    "    minda = pd.concat(( mind, age), axis = 1 , join = 'inner' )  # this will drop all the na columns\n",
    "    mindat = pd.concat(( minda, datenums), axis = 1) #add sequential dates\n",
    "    mindata = pd.concat(( mindat, numbooked), axis = 1 , join = 'inner') #add sequential date booked\n",
    "    mindata2 = pd.concat((mindata, mn) , join = 'inner' , axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def dayssince(x):\n",
    "    import matplotlib.dates as dates\n",
    "    return dates.datestr2num(x)\n",
    "data['num_created'] = data['date_account_created'].apply(dayssince)\n",
    "data['num_booked'] = data['date_first_booking'].dropna().apply(dayssince) #subset of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "droprow.axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def onehots():\n",
    "    ohe = pd.get_dummies(data[['gender' , 'signup_method', 'signup_flow' , 'language' , 'affiliate_channel' , 'affiliate_provider' , 'first_affiliate_tracked', 'signup_app', 'first_device_type' , 'first_browser' ]])\n",
    "    ohetest = pd.get_dummies(datatest[['gender' , 'signup_method', 'signup_flow' , 'language' , 'affiliate_channel' , 'affiliate_provider' , 'first_affiliate_tracked', 'signup_app', 'first_device_type' , 'first_browser' ]])\n",
    "    return ohe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def comonlevels(ohe,ohetest):\n",
    "        ##now i can train on ohe and test on testdata because they have the same number of columns and the same name of columns\n",
    "        inboth = []\n",
    "        for i in range(len(ohetest.axes[1])):\n",
    "            if ohetest.axes[1][i]  in  ohe.axes[1]:\n",
    "                inboth.append(ohetest.axes[1][i])\n",
    "        intrain = ohe[inboth].axes[1]\n",
    "        ina = ohe[inboth]\n",
    "        out = []\n",
    "        for i in range(len(ohe.axes[1])):\n",
    "            if ohe.axes[1][i] not in intrain:\n",
    "                out.append(ohe.axes[1][i])\n",
    "        for i in out:\n",
    "            ina.loc[:,i] = 0\n",
    "        testdata = ina\n",
    "        return testdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def createBarcharts(data):\n",
    "        female_destinations = data.loc[data['gender'] == 'FEMALE' , 'country_destination' ].value_counts() ##value counts is a datafrmae, without it is a series\n",
    "        female_destinations.plot('bar', color='r',  position = 0,label = 'feMale' )\n",
    "        male_destination = data.loc[data['gender'] == 'MALE' , 'country_destination' ].value_counts() ##value counts is a datafrmae, without it is a series\n",
    "        male_destination.plot('bar', color = 'b' , position = 1 , label = 'Male')\n",
    "        #male_destination = data.loc[data['gender'] == 'other' , 'country_destination' ].value_counts() ##value counts is a datafrmae, without it is a series\n",
    "        unknown_destinations = data.loc[data['gender'] == '-unknown-' , 'country_destination' ].value_counts() ##value counts is a datafrmae, without it is a series\n",
    "        #male_destination.plot('bar', color = 'b' , position = 1 , label = 'Male')\n",
    "        unknown_destinations.plot('bar', color='g',  position = 0.5,label = 'feMale' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def allvcounts(data):\n",
    "    aggregate = pd.DataFrame(np.empty((0,0)))\n",
    "    for attribute in data.axes[1]:\n",
    "        tolist = data.loc[ :  , attribute ] .value_counts()\n",
    "        aggregate = pd.concat((aggregate , tolist) , axis = 1)\n",
    "    return aggregae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def otherunk(data):\n",
    "    other_destination = data.loc[data['gender'] == 'other' , 'country_destination' ].value_counts() ##value counts is a datafrmae, without it is a series\n",
    "    unknown_destinations = data.loc[data['gender'] == '-unknown-' , 'country_destination' ].value_counts() ##value counts is a datafrmae, without it is a series\n",
    "    a = other_destination.plot('bar', color = 'b' , position = 1 , label = 'Male')\n",
    "    b = unknown_destinations.plot('bar', color='r',  position = 0.25,label = 'feMale' )\n",
    "    return a ,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##create a one hot encodeing of all categorical variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.dates as dates\n",
    "data['date_first_booking']\n",
    "dates.datestr2num(data['date_first_booking'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ata['age'].fillna(-1)\n",
    "#data['date_first_booking'].fillna(-1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#split into train and test set\n",
    "ohe = pd.concat((ohe, data[['year_created' , 'month_created' , 'date_created' , 'year_booked', 'month_booked' , 'day_booked']]))\n",
    "allb = ohe.loc[data['year_booked'] != -1 , :]\n",
    "allb = allb.fillna(0)\n",
    "valid = allb.iloc[0:10000 , :]\n",
    "train = allb.iloc[10000:: , :]\n",
    "dt = pd.concat((data['country_destination'] ,allb , ))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mindata.axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#ohe , testdata are my two datasets not spilit into valid set\n",
    "svc = SVC()\n",
    "#sgd = SGDClassifier()\n",
    "svc.fit(train , train_y).score(valid, valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allb = allb.fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.age.dropna().value_counts().plot(kind = 'hist' ,bins = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(data.age.dropna()).plot(kind ='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#create age percentiles\n",
    "oldest = data.loc[data.age>42  , 'country_destination']\n",
    "#middleupper = pd.concat((data.age<=42,data.age>33) , join = 'inner')\n",
    "#data.age>33\n",
    "#three = data.age<=33\n",
    "#tweight = data.age>28\n",
    "#middleyoung = pd.concat ( (pd.concat((three, tweight) , join = 'inner') , data['country_destination']) , join = 'inner')\n",
    "youngest = data.loc[data.age<=28 , 'country_destination']\n",
    "#midupper = data.loc[33<data.age<=42, 'country_destination']\n",
    "old2 = data.loc[data.age<=33 , 'country_destination']\n",
    "young2 = data.loc[data.age>33 , 'country_destination']\n",
    "\n",
    "oldest.value_counts().plot('bar' ,color = 'b', position = 0)\n",
    "youngest.value_counts().plot('bar', color = 'r', position = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# oldest and youngest vs country pref\n",
    "\n",
    "#middleupper.value_counts().plot('bar', color = 'g' , position = 2)\n",
    "#middleyoung.value_counts().plot('bar', color = 'y' , position = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##young and old raw vs country pref\n",
    "old2.value_counts().plot('bar' , color = 'b' , position = 0)\n",
    "young2.value_counts().plot('bar' , color = 'r' , position = 1)\n",
    "total = len(data['gender'])\n",
    "totalold = len(old2)\n",
    "totalyoung = len(young2)\n",
    "centold = old2.value_counts()/totalold\n",
    "centyoung = young2.value_counts()/totalyoung\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## get years and months as a number so it can be a category \n",
    "def getyear(x):\n",
    "    if type(x) == float:\n",
    "        return -1\n",
    "    else :\n",
    "        return int(x[0:4])\n",
    "def getmonth(x):\n",
    "    if type(x) == float:\n",
    "        return -1\n",
    "    else :\n",
    "        return int(x[5:7])\n",
    "def getday(x):\n",
    "    if type(x) == float:\n",
    "        return -1\n",
    "    else :\n",
    "        return int(x[8:11])\n",
    "def getorder(x):\n",
    "    return( (x[0:4],x[5:7],x[8:11]) )\n",
    "def getdate(x):\n",
    "    return datetime.date(x).toordinal()\n",
    "##add the column to data \n",
    "data['date_account_created2'] = data['date_account_created'].apply(getorder)\n",
    "data['year_created'] = data['date_account_created'].apply(getyear)\n",
    "data['month_created'] = data['date_account_created'].apply(getmonth)\n",
    "data['date_created'] = data['date_account_created'].apply(getday)\n",
    "data['year_booked'] = data['date_first_booking'].apply(getyear)\n",
    "data['month_booked'] = data['date_first_booking'].apply(getmonth)\n",
    "data['day_booked'] = data['date_first_booking'].apply(getday)\n",
    "#ohe = pd.concat((ohe, data[['year_created' , 'month_created' , 'date_created' , 'year_booked', 'month_booked' , 'day_booked']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "centold.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allbooked = ohe.loc[data['year_booked'] != -1 , :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allbooked.axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ohe.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ohe = pd.concat((ohe, data[['year_created' , 'month_created' , 'date_created' , 'year_booked', 'month_booked' , 'day_booked']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dates= data[['year_created' , 'month_created' , 'date_created' , 'year_booked', 'month_booked' , 'day_booked']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dates.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##every month i want  to create a bin \n",
    "dates[['month_created' , 'year_created' ]].plot(kind = 'bar')\n",
    "##i want number of signups to be on the x-axis , \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def timeplots(datenums,numbooked):\n",
    "    datenums.plot(kind = 'hist')\n",
    "    numbooked.plot(kind = 'hist' , bins = 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "( data['age'] < 100 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#plt.hist(datenums, bins = 20) \n",
    "try:\n",
    "    plt.hist(numbooked['date_first_booking'])\n",
    "except: KeyError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "total = len(data['language'] .dropna())\n",
    "n = 0\n",
    "def languageplot(data):\n",
    "    percentsnon = data.loc[data['language'] != 'en' , 'country_destination'].value_counts()/total\n",
    "    percentsen = data.loc[data['language'] == 'en' , 'country_destination'].value_counts()/total\n",
    "\n",
    "#percents = data.loc[ : , 'country_destination'].value_counts()/total\n",
    "    percentsnon.plot(kind = 'bar' , position = 0, color = 'b')\n",
    "    percentsen.plot(kind = 'bar' , position = 0.5 , color = 'r')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.get_dummies(data[['gender' , 'signup_method', 'signup_flow' , 'language' , 'affiliate_channel' , 'affiliate_provider' , 'first_affiliate_tracked', 'signup_app', 'first_device_type' , 'first_browser' ]]).axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.loc['language' =='en'  , 'country_destination']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#old2 = data.loc[data.gender , 'country_destination']\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data['language']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc = SVC()\n",
    "#sgd = SGDClassifier()\n",
    "svc.fit(train , trainy).score(valid, validy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=600,max_depth = 6, criterion='gini')\n",
    "rf.fit(train , trainy).score(valid, validy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(trainy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(data.iloc[0:10000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mindata = pd.get_dummies(nndata[['gender']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
